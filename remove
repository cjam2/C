import os, json, time, datetime
import requests
import urllib3
import getpass
from requests.auth import HTTPBasicAuth

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def _sync_meta_path(data_dir: str) -> str:
    return os.path.join(data_dir, "sync_meta.json")

def _load_last_sync(data_dir: str):
    p = _sync_meta_path(data_dir)
    if not os.path.exists(p):
        return None
    try:
        with open(p, "r", encoding="utf-8") as f:
            meta = json.load(f)
        return meta.get("last_sync_cql_time")  # string
    except Exception:
        return None

def _save_last_sync(data_dir: str, last_sync_str: str, page_count: int):
    meta = {
        "last_sync_cql_time": last_sync_str,
        "synced_at_epoch": time.time(),
        "page_count_last_run": page_count
    }
    with open(_sync_meta_path(data_dir), "w", encoding="utf-8") as f:
        json.dump(meta, f, indent=2)

def _format_confluence_cql_time(dt: datetime.datetime) -> str:
    # Confluence CQL supports date/time strings; this format is widely accepted.
    # Example: 2026-02-27 21:30
    return dt.strftime("%Y-%m-%d %H:%M")

def _build_effective_cql(cfg, data_dir: str) -> str:
    base_cql = cfg["cql"].strip()
    if not cfg.get("incremental_sync", False):
        return base_cql

    last_sync = _load_last_sync(data_dir)
    if not last_sync:
        return base_cql

    # Wrap base query to preserve precedence, then append lastmodified filter
    return f"({base_cql}) AND lastmodified > \"{last_sync}\""

def sync_confluence(cfg):
    base = cfg["confluence_base_url"].rstrip("/")
    limit = int(cfg.get("limit", 50))

    data_dir = cfg.get("data_dir", "./data")
    os.makedirs(data_dir, exist_ok=True)
    raw_dir = os.path.join(data_dir, "raw_pages")
    os.makedirs(raw_dir, exist_ok=True)

    effective_cql = _build_effective_cql(cfg, data_dir)

    # Prompt for credentials (masked)
    user = input("Confluence user: ")
    pw = getpass.getpass("Confluence password: ")
    auth = HTTPBasicAuth(user, pw)

    pages = []
    start = 0

    while True:
        url = f"{base}/rest/api/content/search"
        params = {
            "cql": effective_cql,
            "start": start,
            "limit": limit,
            "expand": "body.storage,version,space,_links"
        }

        r = requests.get(
            url,
            params=params,
            auth=auth,
            headers={"Accept": "application/json"},
            timeout=60,
            verify=False  # local dev only
        )

        r.raise_for_status()
        payload = r.json()
        results = payload.get("results", [])

        if not results:
            break

        for p in results:
            pid = p["id"]
            title = p.get("title", "")
            space = p.get("space", {}).get("key", "")
            when = p.get("version", {}).get("when", "")
            html = p.get("body", {}).get("storage", {}).get("value", "")

            links = p.get("_links", {})
            webui = links.get("webui", "")
            url_page = f"{base}{webui}" if webui else base

            rec = {
                "id": pid,
                "title": title,
                "space": space,
                "updated": when,
                "url": url_page,
                "html": html
            }

            pages.append(rec)

            with open(os.path.join(raw_dir, f"{pid}.json"), "w", encoding="utf-8") as f:
                json.dump(rec, f, ensure_ascii=False)

        start += len(results)
        if len(results) < limit:
            break

    # Save last sync time as "now" for next incremental run
    now_str = _format_confluence_cql_time(datetime.datetime.now())
    _save_last_sync(data_dir, now_str, len(pages))

    return pages

if __name__ == "__main__":
    with open("config.json", "r", encoding="utf-8") as f:
        cfg = json.load(f)

    pages = sync_confluence(cfg)
    print(f"Synced {len(pages)} pages.")
