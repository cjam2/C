import os
import json
import streamlit as st

from sync_confluence import sync_confluence
from chunking import html_to_text, chunk_words
from indexer import build_bm25, search_bm25

# -----------------------------
# Robust config loading
# -----------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG_PATH = os.path.join(BASE_DIR, "config.json")

if not os.path.exists(CONFIG_PATH):
    raise FileNotFoundError(
        f"config.json not found at: {CONFIG_PATH}\n"
        f"Make sure config.json is in the same folder as app.py"
    )

with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    cfg = json.load(f)

# -----------------------------
# Directories / settings
# -----------------------------
DATA_DIR = cfg.get("data_dir", "./data")
if not os.path.isabs(DATA_DIR):
    DATA_DIR = os.path.join(BASE_DIR, DATA_DIR)

os.makedirs(DATA_DIR, exist_ok=True)

CHUNKS_PATH = os.path.join(DATA_DIR, "chunks_meta.jsonl")

CHUNK_SIZE = int(cfg.get("chunk_words", 250))
OVERLAP = int(cfg.get("chunk_overlap", 50))
TOP_K = int(cfg.get("top_k", 8))

# -----------------------------
# Streamlit config + session state
# -----------------------------
st.set_page_config(page_title="Confluence Doc Search (Local)", layout="wide")
st.title("Confluence Doc Search (Phase 1 — Local, No LLM)")
st.caption("Search Confluence docs locally and jump to the exact section. No generation, no hallucinations.")

if "chunks_meta" not in st.session_state:
    st.session_state.chunks_meta = None

if "bm25" not in st.session_state:
    st.session_state.bm25 = None

# -----------------------------
# Helpers: save/load cached chunks
# -----------------------------
def save_chunks(chunks_meta):
    with open(CHUNKS_PATH, "w", encoding="utf-8") as f:
        for item in chunks_meta:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")

def load_chunks():
    if not os.path.exists(CHUNKS_PATH):
        return None
    chunks = []
    with open(CHUNKS_PATH, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            chunks.append(json.loads(line))
    return chunks

# -----------------------------
# Auto-load cached index on startup
# -----------------------------
if st.session_state.chunks_meta is None:
    cached = load_chunks()
    if cached:
        st.session_state.chunks_meta = cached
        st.session_state.bm25 = build_bm25(cached)

# -----------------------------
# UI Layout
# -----------------------------
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("Sync / Index")

    st.write("This pulls Confluence pages using your CQL and builds a local BM25 index.")
    st.code(cfg.get("cql", ""), language="sql")

    if st.button("Sync Now"):
        with st.spinner("Syncing Confluence and building index..."):
            progress = st.progress(0)
            status = st.empty()

            # Pull pages
            pages = sync_confluence(cfg)
            total_pages = max(1, len(pages))

            chunks_meta = []

            # Build chunks
            for i, p in enumerate(pages, 1):
                title = p.get("title", "")
                status.write(f"Processing page {i}/{total_pages}: {title}")

                text = html_to_text(p.get("html", ""))
                chunks = chunk_words(text, chunk_size=CHUNK_SIZE, overlap=OVERLAP)

                for c in chunks:
                    chunks_meta.append({
                        "title": p.get("title", ""),
                        "space": p.get("space", ""),
                        "updated": p.get("updated", ""),
                        "url": p.get("url", ""),
                        "chunk": c
                    })

                progress.progress(int(i / total_pages * 100))

            # Build BM25
            bm25 = build_bm25(chunks_meta)

            # Save to session + disk cache
            st.session_state.chunks_meta = chunks_meta
            st.session_state.bm25 = bm25
            save_chunks(chunks_meta)

            progress.progress(100)
            status.write("✅ Done.")
            st.success(f"Indexed {len(chunks_meta)} chunks from {len(pages)} pages.")
            st.info(f"Cached chunks saved to: {CHUNKS_PATH}")

    st.markdown("### Index status")
    if st.session_state.bm25 is None:
        st.warning("No index loaded. Click **Sync Now**.")
    else:
        st.success("Index is loaded and ready to search.")
        if st.session_state.chunks_meta:
            st.write(f"Chunks loaded: **{len(st.session_state.chunks_meta)}**")

    if os.path.exists(CHUNKS_PATH):
        st.write("Cache file found ✅")
    else:
        st.write("Cache file not found yet (will be created after first sync).")

    if st.button("Clear Local Cache"):
        if os.path.exists(CHUNKS_PATH):
            os.remove(CHUNKS_PATH)
        st.session_state.chunks_meta = None
        st.session_state.bm25 = None
        st.success("Cache cleared. Please Sync again.")

with col2:
    st.subheader("Search")
    q = st.text_input("Ask a question / type keywords:")

    if st.button("Search") and q:
        if st.session_state.bm25 is None or st.session_state.chunks_meta is None:
            st.error("No index loaded. Click **Sync Now** first.")
        else:
            results = search_bm25(q, st.session_state.bm25, st.session_state.chunks_meta, top_k=TOP_K)

            if not results:
                st.warning("No strong matches found. Try different keywords or widen your CQL scope.")
            else:
                st.write(f"Top results: **{len(results)}**")
                for i, r in enumerate(results, 1):
                    st.markdown(f"### {i}. {r.get('title','')}")
                    st.write(
                        f"**Space:** {r.get('space','')}  |  "
                        f"**Updated:** {r.get('updated','')}  |  "
                        f"**Score:** {r.get('score',0):.2f}"
                    )
                    chunk = r.get("chunk", "")
                    st.write(chunk[:900] + ("..." if len(chunk) > 900 else ""))
                    url = r.get("url", "")
                    if url:
                        st.markdown(f"[Open in Confluence]({url})")
                    st.divider()
