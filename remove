import os
import json
import streamlit as st
import concurrent.futures

from sync_confluence import sync_confluence
from chunking import html_to_text, chunk_words
from indexer import build_bm25, search_bm25, tokenize

# -----------------------------
# Config Loading
# -----------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG_PATH = os.path.join(BASE_DIR, "config.json")

if not os.path.exists(CONFIG_PATH):
    raise FileNotFoundError(f"config.json not found at {CONFIG_PATH}")

with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    cfg = json.load(f)

DATA_DIR = cfg.get("data_dir", "./data")
if not os.path.isabs(DATA_DIR):
    DATA_DIR = os.path.join(BASE_DIR, DATA_DIR)
os.makedirs(DATA_DIR, exist_ok=True)

CHUNKS_PATH = os.path.join(DATA_DIR, "chunks_meta.jsonl")

CHUNK_SIZE = int(cfg.get("chunk_words", 250))
OVERLAP = int(cfg.get("chunk_overlap", 50))
TOP_K = int(cfg.get("top_k", 8))

# -----------------------------
# Streamlit Setup
# -----------------------------
st.set_page_config(page_title="Confluence Doc Search", layout="wide")
st.title("Confluence Internal Doc Search (Local BM25)")
st.caption("Fully local. No external models. No hallucination.")

# -----------------------------
# Session State
# -----------------------------
if "chunks_meta" not in st.session_state:
    st.session_state.chunks_meta = None

if "bm25" not in st.session_state:
    st.session_state.bm25 = None

if "syncing" not in st.session_state:
    st.session_state.syncing = False

if "sync_msg" not in st.session_state:
    st.session_state.sync_msg = ""

# -----------------------------
# Cache Helpers
# -----------------------------
def save_chunks(chunks_meta):
    with open(CHUNKS_PATH, "w", encoding="utf-8") as f:
        for item in chunks_meta:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")

def load_chunks():
    if not os.path.exists(CHUNKS_PATH):
        return None
    chunks = []
    with open(CHUNKS_PATH, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                chunks.append(json.loads(line))
    return chunks

# -----------------------------
# Parallel Page Processing (Upgrade C)
# -----------------------------
def process_page_to_chunks(p, chunk_size, overlap):
    text = html_to_text(p.get("html", ""))
    chunks = chunk_words(text, chunk_size=chunk_size, overlap=overlap)

    out = []
    for c in chunks:
        out.append({
            "page_id": p.get("id", ""),
            "title": p.get("title", ""),
            "space": p.get("space", ""),
            "updated": p.get("updated", ""),
            "url": p.get("url", ""),
            "chunk": c,
            "tokens": tokenize(c)  # Upgrade B
        })
    return out

# -----------------------------
# Auto Load Existing Index
# -----------------------------
if st.session_state.chunks_meta is None:
    cached = load_chunks()
    if cached:
        st.session_state.chunks_meta = cached
        st.session_state.bm25 = build_bm25(cached)

# -----------------------------
# Layout
# -----------------------------
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("Sync / Index")

    st.code(cfg.get("cql", ""), language="sql")

    conf_user = st.text_input("Confluence user")
    conf_pass = st.text_input("Confluence password", type="password")

    if st.button("Sync Now"):
        st.session_state.syncing = True
        st.session_state.sync_msg = ""
        st.rerun()

    if st.session_state.syncing:
        with st.spinner("Syncing Confluence and building index..."):
            progress = st.progress(0)
            status = st.empty()

            if not conf_user or not conf_pass:
                progress.progress(100)
                st.session_state.sync_msg = "❌ Enter credentials."
                st.session_state.syncing = False
                st.rerun()

            pages = sync_confluence(cfg, conf_user, conf_pass)

            if not pages:
                progress.progress(100)
                st.session_state.sync_msg = "✅ No updated pages found."
                st.session_state.syncing = False
                st.rerun()

            total_pages = len(pages)
            chunks_meta_new = []

            max_workers = min(16, (os.cpu_count() or 4))
            status.write(f"Parallel processing with {max_workers} workers...")

            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as ex:
                futures = {
                    ex.submit(process_page_to_chunks, p, CHUNK_SIZE, OVERLAP): p
                    for p in pages
                }

                done_count = 0
                for fut in concurrent.futures.as_completed(futures):
                    p = futures[fut]
                    try:
                        page_chunks = fut.result()
                        chunks_meta_new.extend(page_chunks)
                    except Exception as e:
                        status.write(f"⚠ Failed page: {p.get('title','')} — {e}")

                    done_count += 1
                    progress.progress(int(done_count / total_pages * 100))

            # Merge incremental updates
            existing = load_chunks() or []
            changed_ids = {x["page_id"] for x in chunks_meta_new if x.get("page_id")}
            existing = [x for x in existing if x.get("page_id") not in changed_ids]

            combined = existing + chunks_meta_new

            bm25 = build_bm25(combined)

            st.session_state.chunks_meta = combined
            st.session_state.bm25 = bm25
            save_chunks(combined)

            progress.progress(100)
            st.session_state.sync_msg = f"✅ Sync complete. Updated {len(changed_ids)} pages. Total chunks: {len(combined)}."
            st.session_state.syncing = False
            st.rerun()

    if st.session_state.sync_msg:
        st.info(st.session_state.sync_msg)

    st.markdown("### Index Status")
    if st.session_state.bm25:
        st.success(f"Index loaded: {len(st.session_state.chunks_meta)} chunks")
    else:
        st.warning("No index loaded yet.")

    if st.button("Clear Cache"):
        if os.path.exists(CHUNKS_PATH):
            os.remove(CHUNKS_PATH)
        st.session_state.chunks_meta = None
        st.session_state.bm25 = None
        st.session_state.sync_msg = "Cache cleared."
        st.rerun()

# -----------------------------
# Search UI
# -----------------------------
with col2:
    st.subheader("Search")

    q = st.text_input("Enter keywords")

    if st.button("Search") and q:
        if not st.session_state.bm25:
            st.error("No index loaded. Sync first.")
        else:
            results = search_bm25(q, st.session_state.bm25, st.session_state.chunks_meta, TOP_K)

            if not results:
                st.warning("No matches found.")
            else:
                for i, r in enumerate(results, 1):
                    st.markdown(f"### {i}. {r['title']}")
                    st.write(f"Space: {r['space']} | Updated: {r['updated']} | Score: {r['score']:.2f}")
                    st.write(r["chunk"][:900] + ("..." if len(r["chunk"]) > 900 else ""))
                    if r.get("url"):
                        st.markdown(f"[Open in Confluence]({r['url']})")
                    st.divider()
